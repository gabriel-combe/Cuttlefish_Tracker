% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.1 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{rlabbe}{online}{}
      \name{author}{1}{}{%
        {{hash=69c51f9374cce2ab10da10523b4a64db}{%
           family={(rlabbe)},
           familyi={(\bibinitperiod},
           given={Roger\bibnamedelima Labbe},
           giveni={R\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {GitHub}%
      }
      \strng{namehash}{69c51f9374cce2ab10da10523b4a64db}
      \strng{fullhash}{69c51f9374cce2ab10da10523b4a64db}
      \strng{bibnamehash}{69c51f9374cce2ab10da10523b4a64db}
      \strng{authorbibnamehash}{69c51f9374cce2ab10da10523b4a64db}
      \strng{authornamehash}{69c51f9374cce2ab10da10523b4a64db}
      \strng{authorfullhash}{69c51f9374cce2ab10da10523b4a64db}
      \field{sortinit}{r}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{GitHub repository}
      \field{title}{Kalman and Bayesian Filters in Python}
      \field{year}{2014}
      \verb{urlraw}
      \verb https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python
      \endverb
      \verb{url}
      \verb https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python
      \endverb
    \endentry
    \entry{bhattacharyya_measure_1960}{article}{}
      \name{author}{1}{}{%
        {{hash=5849c9038498843b9de5403c4033f171}{%
           family={Bhattacharyya},
           familyi={B\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{5849c9038498843b9de5403c4033f171}
      \strng{fullhash}{5849c9038498843b9de5403c4033f171}
      \strng{bibnamehash}{5849c9038498843b9de5403c4033f171}
      \strng{authorbibnamehash}{5849c9038498843b9de5403c4033f171}
      \strng{authornamehash}{5849c9038498843b9de5403c4033f171}
      \strng{authorfullhash}{5849c9038498843b9de5403c4033f171}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Sankhyā: The Indian Journal of Statistics (1933-1960)}
      \field{number}{4}
      \field{title}{On a {Measure} of {Divergence} between {Two} {Multinomial} {Populations}}
      \field{volume}{7}
      \field{year}{1960}
      \field{pages}{401\bibrangedash 406}
      \range{pages}{6}
    \endentry
    \entry{dalal_histograms_2005}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=521763e082baf91e4935f956c6c0f8b3}{%
           family={Dalal},
           familyi={D\bibinitperiod},
           given={N.},
           giveni={N\bibinitperiod}}}%
        {{hash=d90650ec8434180101eb4aeec8e4a0c6}{%
           family={Triggs},
           familyi={T\bibinitperiod},
           given={B.},
           giveni={B\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {San Diego, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{8316a8a4748fedae6ff9c5414cecc95a}
      \strng{fullhash}{8316a8a4748fedae6ff9c5414cecc95a}
      \strng{bibnamehash}{8316a8a4748fedae6ff9c5414cecc95a}
      \strng{authorbibnamehash}{8316a8a4748fedae6ff9c5414cecc95a}
      \strng{authornamehash}{8316a8a4748fedae6ff9c5414cecc95a}
      \strng{authorfullhash}{8316a8a4748fedae6ff9c5414cecc95a}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors signiﬁcantly outperform existing feature sets for human detection. We study the inﬂuence of each stage of the computation on performance, concluding that ﬁne-scale gradients, ﬁne orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.}
      \field{booktitle}{2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)}
      \field{title}{Histograms of {Oriented} {Gradients} for {Human} {Detection}}
      \field{volume}{1}
      \field{year}{2005}
      \field{pages}{886\bibrangedash 893}
      \range{pages}{8}
    \endentry
    \entry{pp2pf}{online}{}
      \name{author}{4}{}{%
        {{hash=f1cb584bef3901a9147d127dc802e491}{%
           family={Gabriel},
           familyi={G\bibinitperiod},
           given={Combe-Ounkham},
           giveni={C\bibinithyphendelim O\bibinitperiod}}}%
        {{hash=7922c6155fa0676f25d56c9d15c4eed4}{%
           family={Ariane},
           familyi={A\bibinitperiod},
           given={Vaisse},
           giveni={V\bibinitperiod}}}%
        {{hash=7cb599d7e32f385a3c1707a2c74384fd}{%
           family={Maxime},
           familyi={M\bibinitperiod},
           given={Beldjilali},
           giveni={B\bibinitperiod}}}%
        {{hash=9303aa9a00ce98ba225fc2c0e1019c9b}{%
           family={Luis-Miguel},
           familyi={L\bibinithyphendelim M\bibinitperiod},
           given={Young\bibnamedelima Brun},
           giveni={Y\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {GitHub}%
      }
      \strng{namehash}{14a5ce5326c41cc2bba4f0053c0cca9a}
      \strng{fullhash}{802e6337565b14504d1a595553a92907}
      \strng{bibnamehash}{14a5ce5326c41cc2bba4f0053c0cca9a}
      \strng{authorbibnamehash}{14a5ce5326c41cc2bba4f0053c0cca9a}
      \strng{authornamehash}{14a5ce5326c41cc2bba4f0053c0cca9a}
      \strng{authorfullhash}{802e6337565b14504d1a595553a92907}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{GitHub repository}
      \field{title}{PP2 Particle Filter}
      \field{year}{2023}
      \verb{urlraw}
      \verb https://github.com/gabriel-combe/PP2_Particle_Filter
      \endverb
      \verb{url}
      \verb https://github.com/gabriel-combe/PP2_Particle_Filter
      \endverb
    \endentry
    \entry{kong_particle_2019}{article}{}
      \name{author}{6}{}{%
        {{hash=1c92bea464d4e5a19e0ff469c8ed7076}{%
           family={Kong},
           familyi={K\bibinitperiod},
           given={Xiaofang},
           giveni={X\bibinitperiod}}}%
        {{hash=b6fff56e4c606d8c37bb384da63c33e3}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Qian},
           giveni={Q\bibinitperiod}}}%
        {{hash=27a7d8677dd7308dbc00a024300db05d}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Guohua},
           giveni={G\bibinitperiod}}}%
        {{hash=e60df921d205387a6a076dca1c8f329b}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Kan},
           giveni={K\bibinitperiod}}}%
        {{hash=c1bf42238e78c95c69147f026e73790b}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Weixian},
           giveni={W\bibinitperiod}}}%
        {{hash=1d7a874b1ff656ee5f33ddd7918b2fd4}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Zewei},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{dcfd1d5aba7418991c6bb5864593b743}
      \strng{fullhash}{f8a8c948b635cbe3aa1808ef7f427f6d}
      \strng{bibnamehash}{dcfd1d5aba7418991c6bb5864593b743}
      \strng{authorbibnamehash}{dcfd1d5aba7418991c6bb5864593b743}
      \strng{authornamehash}{dcfd1d5aba7418991c6bb5864593b743}
      \strng{authorfullhash}{f8a8c948b635cbe3aa1808ef7f427f6d}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Tracking vehicles automatically are of great importance in the intelligent transportation systems to guarantee the traffic safety, especially for the self-driving technique. To solve the problem of the tiny jitter of the camera due to the shaking platform and the rough road, and to track the vehicle ahead, a salient feature-based video stabilisation method is introduced to remove the effect of camera motion, and an improved particle filter-based vehicle tracking algorithm via histogram of oriented gradient (HOG) features is proposed in this study. For video stabilisation, first, the features from accelerated segment test algorithm are applied to extract salient points from the two adjacent frames. Then, the fast retina keypoint algorithm is used to match the correspondences and the M-estimator sample consensus algorithm is applied to remove the outliers. Finally, the image with tiny jitter is stabilised by the affine transformation matrix calculated from the retained inliers. After the image stabilisation, an improved particle filter-based tracking method is proposed for vehicle tracking via the HOG feature extracted from an adaptive searching area determined by the expected vehicle position of the previous frame. Experimental results demonstrate that camera motion can be effectively compensated by the feature-based stabilisation method, and the forward vehicle can be tracked with stability and robustness in real time.}
      \field{journaltitle}{IET Intelligent Transport Systems}
      \field{month}{6}
      \field{number}{6}
      \field{title}{Particle filter‐based vehicle tracking via {HOG} features after image stabilisation in intelligent drive system}
      \field{volume}{13}
      \field{year}{2019}
      \field{pages}{942\bibrangedash 949}
      \range{pages}{8}
    \endentry
    \entry{liu_ssd_2016}{incollection}{}
      \name{author}{7}{}{%
        {{hash=c0e0d23e2d09e45e6f51cc2bcea6d9f9}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=c1826f3465579186aff299a9b0e16ed7}{%
           family={Anguelov},
           familyi={A\bibinitperiod},
           given={Dragomir},
           giveni={D\bibinitperiod}}}%
        {{hash=8bbc4c5d96f205bada839e74e0202146}{%
           family={Erhan},
           familyi={E\bibinitperiod},
           given={Dumitru},
           giveni={D\bibinitperiod}}}%
        {{hash=ed568d9c3bb059e6bf22899fbf170f86}{%
           family={Szegedy},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=698ee61a2f3fa29734204496d2d36aef}{%
           family={Reed},
           familyi={R\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod}}}%
        {{hash=ec820780d594e36d11c6e30c7a2614e0}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Cheng-Yang},
           giveni={C\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=963e9b2526a7150c418b4e9e9d19a82f}{%
           family={Berg},
           familyi={B\bibinitperiod},
           given={Alexander\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{623b50f45b666c1e9b84e5228e255810}
      \strng{fullhash}{d5e1ac3dfe6687980f91e701611520ad}
      \strng{bibnamehash}{623b50f45b666c1e9b84e5228e255810}
      \strng{authorbibnamehash}{623b50f45b666c1e9b84e5228e255810}
      \strng{authornamehash}{623b50f45b666c1e9b84e5228e255810}
      \strng{authorfullhash}{d5e1ac3dfe6687980f91e701611520ad}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets conﬁrm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a uniﬁed framework for both training and inference. For 300 × 300 input, SSD achieves 74.3\% mAP1 on VOC2007 test at 59 FPS on a Nvidia Titan X and for 512 × 512 input, SSD achieves 76.9\% mAP, outperforming a comparable state-of-the-art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at: https://github.com/weiliu89/caffe/tree/ssd .}
      \field{annotation}{Comment: ECCV 2016}
      \field{shorttitle}{{SSD}}
      \field{title}{{SSD}: {Single} {Shot} {MultiBox} {Detector}}
      \field{volume}{9905}
      \field{year}{2016}
      \field{pages}{21\bibrangedash 37}
      \range{pages}{17}
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{qiang_zhu_fast_2006}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=095f784b151ef6e1ae92d614829f6e98}{%
           family={{Qiang Zhu}},
           familyi={Q\bibinitperiod}}}%
        {{hash=1950be5a07a5acf5c3474c6fd31f977f}{%
           family={{Mei-Chen Yeh}},
           familyi={M\bibinitperiod}}}%
        {{hash=4f893eccdd9d4c97ff19d5a0864862d7}{%
           family={{Kwang-Ting Cheng}},
           familyi={K\bibinitperiod}}}%
        {{hash=fe2d341c406b58a815582066e8375730}{%
           family={Avidan},
           familyi={A\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{1f56413fa0438ed7bc3c458757a54f82}
      \strng{fullhash}{5a5415d11d7fd7f0f34c1af0122a8919}
      \strng{bibnamehash}{1f56413fa0438ed7bc3c458757a54f82}
      \strng{authorbibnamehash}{1f56413fa0438ed7bc3c458757a54f82}
      \strng{authornamehash}{1f56413fa0438ed7bc3c458757a54f82}
      \strng{authorfullhash}{5a5415d11d7fd7f0f34c1af0122a8919}
      \field{sortinit}{Q}
      \field{sortinithash}{ce69a400a872ddd02ee7fdb3b38c6abd}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We integrate the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features to achieve a fast and accurate human detection system. The features used in our system are HoGs of variable-size blocks that capture salient features of humans automatically. Using AdaBoost for feature selection, we identify the appropriate set of blocks, from a large set of possible blocks. In our system, we use the integral image representation and a rejection cascade which signiﬁcantly speed up the computation. For a 320 × 280 image, the system can process 5 to 30 frames per second depending on the density in which we scan the image, while maintaining an accuracy level similar to existing methods.}
      \field{booktitle}{2006 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} - {Volume} 2 ({CVPR}'06)}
      \field{title}{Fast {Human} {Detection} {Using} a {Cascade} of {Histograms} of {Oriented} {Gradients}}
      \field{volume}{2}
      \field{year}{2006}
      \field{pages}{1491\bibrangedash 1498}
      \range{pages}{8}
    \endentry
    \entry{redmon_you_2016}{misc}{}
      \name{author}{4}{}{%
        {{hash=99bced2e56a5253f3fe98a5f04e6d9b2}{%
           family={Redmon},
           familyi={R\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod}}}%
        {{hash=05ca9f19da9ecbd2def4e5514f8043c8}{%
           family={Divvala},
           familyi={D\bibinitperiod},
           given={Santosh},
           giveni={S\bibinitperiod}}}%
        {{hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod}}}%
        {{hash=396c6ddedb6f986906fc3e4994d19974}{%
           family={Farhadi},
           familyi={F\bibinitperiod},
           given={Ali},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{e1203a0044715040adeb8c5079ee645a}
      \strng{fullhash}{b5530443e433a4da53dbe3cf155225b4}
      \strng{bibnamehash}{e1203a0044715040adeb8c5079ee645a}
      \strng{authorbibnamehash}{e1203a0044715040adeb8c5079ee645a}
      \strng{authornamehash}{e1203a0044715040adeb8c5079ee645a}
      \strng{authorfullhash}{b5530443e433a4da53dbe3cf155225b4}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present YOLO, a new approach to object detection. Prior work on object detection repurposes classiﬁers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.}
      \field{month}{5}
      \field{shorttitle}{You {Only} {Look} {Once}}
      \field{title}{You {Only} {Look} {Once}: {Unified}, {Real}-{Time} {Object} {Detection}}
      \field{year}{2016}
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{yolov7_github}{online}{}
      \name{author}{3}{}{%
        {{hash=053d491932411950eccf2bb9a1025d11}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Chien-Yao},
           giveni={C\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=c0b2fdc20c37a4bd8d817822d374f809}{%
           family={Bochkovskiy},
           familyi={B\bibinitperiod},
           given={Alexey},
           giveni={A\bibinitperiod}}}%
        {{hash=c81478c691c1bc1cc01404c44b5bd5bf}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Hong-Yuan\bibnamedelima Mark},
           giveni={H\bibinithyphendelim Y\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {GitHub}%
      }
      \strng{namehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{fullhash}{9278ecb881789e377b71403c2cf54d74}
      \strng{bibnamehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{authorbibnamehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{authornamehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{authorfullhash}{9278ecb881789e377b71403c2cf54d74}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{GitHub repository}
      \field{title}{YOLOv7}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://github.com/WongKinYiu/yolov7
      \endverb
      \verb{url}
      \verb https://github.com/WongKinYiu/yolov7
      \endverb
    \endentry
    \entry{wang_yolov7_nodate}{article}{}
      \name{author}{3}{}{%
        {{hash=053d491932411950eccf2bb9a1025d11}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Chien-Yao},
           giveni={C\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=c0b2fdc20c37a4bd8d817822d374f809}{%
           family={Bochkovskiy},
           familyi={B\bibinitperiod},
           given={Alexey},
           giveni={A\bibinitperiod}}}%
        {{hash=c81478c691c1bc1cc01404c44b5bd5bf}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Hong-Yuan\bibnamedelima Mark},
           giveni={H\bibinithyphendelim Y\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{fullhash}{9278ecb881789e377b71403c2cf54d74}
      \strng{bibnamehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{authorbibnamehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{authornamehash}{9278ecb881789e377b71403c2cf54d74}
      \strng{authorfullhash}{9278ecb881789e377b71403c2cf54d74}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8\% AP among all known real-time object detectors with 30 FPS or higher on GPU V100. YOLOv7-E6 object detector (56 FPS V100, 55.9\% AP) outperforms both transformer-based detector SWINL Cascade-Mask R-CNN (9.2 FPS A100, 53.9\% AP) by 509\% in speed and 2\% in accuracy, and convolutionalbased detector ConvNeXt-XL Cascade-Mask R-CNN (8.6 FPS A100, 55.2\% AP) by 551\% in speed and 0.7\% AP in accuracy, as well as YOLOv7 outperforms: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B and many other object detectors in speed and accuracy. Moreover, we train YOLOv7 only on MS COCO dataset from scratch without using any other datasets or pre-trained weights. Source code is released in https:// github.com/ WongKinYiu/ yolov7.}
      \field{title}{{YOLOv7}: {Trainable} bag-of-freebies sets new state-of-the-art for real-time object detectors}
    \endentry
    \entry{xu_human_2010}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0a57118bdd031bffda6d1c7fa3abda3b}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Fen},
           giveni={F\bibinitperiod}}}%
        {{hash=afb97708cb4244ee9a5cbc2b4a0cafae}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Ming},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Yantai, China}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{c79b6c864a7c05717bc81ab65b9ddb70}
      \strng{fullhash}{c79b6c864a7c05717bc81ab65b9ddb70}
      \strng{bibnamehash}{c79b6c864a7c05717bc81ab65b9ddb70}
      \strng{authorbibnamehash}{c79b6c864a7c05717bc81ab65b9ddb70}
      \strng{authornamehash}{c79b6c864a7c05717bc81ab65b9ddb70}
      \strng{authorfullhash}{c79b6c864a7c05717bc81ab65b9ddb70}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Human detection and tracking is a task common to many applications, such as video surveillance and security, intelligent vehicles, safety driving, public security, etc. Histogram of oriented gradient (HOG) gives an accurate description of the contour of human body. Based on HOG and support vector machine (SVM) theory, a classifier for pedestrian is obtained. The classifier is then used to find the potential human candidate in the video frame. By calculating the similarity between particle candidates and the target model using Bhattacharyya Coefficient, a tracking algorithm using particle filter is designed and implemented. Experimental results show that the proposed algorithm out-performs Kalman filter based tracking in almost all situations, especially when partial occlusion of object is present.}
      \field{booktitle}{2010 3rd {International} {Congress} on {Image} and {Signal} {Processing}}
      \field{month}{10}
      \field{title}{Human detection and tracking based on {HOG} and particle filter}
      \field{year}{2010}
      \field{pages}{1503\bibrangedash 1507}
      \range{pages}{5}
    \endentry
  \enddatalist
\endrefsection
\endinput

