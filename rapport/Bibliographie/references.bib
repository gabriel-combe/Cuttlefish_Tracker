
@inproceedings{xu_human_2010,
	address = {Yantai, China},
	title = {Human detection and tracking based on {HOG} and particle filter},
	abstract = {Human detection and tracking is a task common to many applications, such as video surveillance and security, intelligent vehicles, safety driving, public security, etc. Histogram of oriented gradient (HOG) gives an accurate description of the contour of human body. Based on HOG and support vector machine (SVM) theory, a classifier for pedestrian is obtained. The classifier is then used to find the potential human candidate in the video frame. By calculating the similarity between particle candidates and the target model using Bhattacharyya Coefficient, a tracking algorithm using particle filter is designed and implemented. Experimental results show that the proposed algorithm out-performs Kalman filter based tracking in almost all situations, especially when partial occlusion of object is present.},
	booktitle = {2010 3rd {International} {Congress} on {Image} and {Signal} {Processing}},
	publisher = {IEEE},
	author = {Xu, Fen and Gao, Ming},
	month = oct,
	year = {2010},
	pages = {1503--1507}
}

@article{kong_particle_2019,
	title = {Particle filter‐based vehicle tracking via {HOG} features after image stabilisation in intelligent drive system},
	volume = {13},
	abstract = {Tracking vehicles automatically are of great importance in the intelligent transportation systems to guarantee the traffic safety, especially for the self-driving technique. To solve the problem of the tiny jitter of the camera due to the shaking platform and the rough road, and to track the vehicle ahead, a salient feature-based video stabilisation method is introduced to remove the effect of camera motion, and an improved particle filter-based vehicle tracking algorithm via histogram of oriented gradient (HOG) features is proposed in this study. For video stabilisation, first, the features from accelerated segment test algorithm are applied to extract salient points from the two adjacent frames. Then, the fast retina keypoint algorithm is used to match the correspondences and the M-estimator sample consensus algorithm is applied to remove the outliers. Finally, the image with tiny jitter is stabilised by the affine transformation matrix calculated from the retained inliers. After the image stabilisation, an improved particle filter-based tracking method is proposed for vehicle tracking via the HOG feature extracted from an adaptive searching area determined by the expected vehicle position of the previous frame. Experimental results demonstrate that camera motion can be effectively compensated by the feature-based stabilisation method, and the forward vehicle can be tracked with stability and robustness in real time.},
	number = {6},
	journal = {IET Intelligent Transport Systems},
	author = {Kong, Xiaofang and Chen, Qian and Gu, Guohua and Ren, Kan and Qian, Weixian and Liu, Zewei},
	month = jun,
	year = {2019},
	pages = {942--949}
}

@inproceedings{qiang_zhu_fast_2006,
	address = {New York, NY, USA},
	title = {Fast {Human} {Detection} {Using} a {Cascade} of {Histograms} of {Oriented} {Gradients}},
	volume = {2},
	abstract = {We integrate the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features to achieve a fast and accurate human detection system. The features used in our system are HoGs of variable-size blocks that capture salient features of humans automatically. Using AdaBoost for feature selection, we identify the appropriate set of blocks, from a large set of possible blocks. In our system, we use the integral image representation and a rejection cascade which signiﬁcantly speed up the computation. For a 320 × 280 image, the system can process 5 to 30 frames per second depending on the density in which we scan the image, while maintaining an accuracy level similar to existing methods.},
	booktitle = {2006 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} - {Volume} 2 ({CVPR}'06)},
	publisher = {IEEE},
	author = {{Qiang Zhu} and {Mei-Chen Yeh} and {Kwang-Ting Cheng} and Avidan, S.},
	year = {2006},
	pages = {1491--1498}
}

@inproceedings{dalal_histograms_2005,
	address = {San Diego, CA, USA},
	title = {Histograms of {Oriented} {Gradients} for {Human} {Detection}},
	volume = {1},
	abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors signiﬁcantly outperform existing feature sets for human detection. We study the inﬂuence of each stage of the computation on performance, concluding that ﬁne-scale gradients, ﬁne orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	publisher = {IEEE},
	author = {Dalal, N. and Triggs, B.},
	year = {2005},
	pages = {886--893}
}

@article{bhattacharyya_measure_1960,
	title = {On a {Measure} of {Divergence} between {Two} {Multinomial} {Populations}},
	volume = {7},
	number = {4},
	journal = {Sankhyā: The Indian Journal of Statistics (1933-1960)},
	author = {Bhattacharyya, A.},
	year = {1960},
	pages = {401--406}
}

@misc{rlabbe,
	author = {Roger Labbe (rlabbe)},
	title = {Kalman and Bayesian Filters in Python},
	year = {2014},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python}
}


@article{wang_yolov7_nodate,
	title = {{YOLOv7}: {Trainable} bag-of-freebies sets new state-of-the-art for real-time object detectors},
	abstract = {YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8\% AP among all known real-time object detectors with 30 FPS or higher on GPU V100. YOLOv7-E6 object detector (56 FPS V100, 55.9\% AP) outperforms both transformer-based detector SWINL Cascade-Mask R-CNN (9.2 FPS A100, 53.9\% AP) by 509\% in speed and 2\% in accuracy, and convolutionalbased detector ConvNeXt-XL Cascade-Mask R-CNN (8.6 FPS A100, 55.2\% AP) by 551\% in speed and 0.7\% AP in accuracy, as well as YOLOv7 outperforms: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B and many other object detectors in speed and accuracy. Moreover, we train YOLOv7 only on MS COCO dataset from scratch without using any other datasets or pre-trained weights. Source code is released in https:// github.com/ WongKinYiu/ yolov7.},
	author = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark}
}
